\documentclass[12pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Bruce Campbell NCSU ST-503 HW 3},
            pdfauthor={Bruce Campbell},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Bruce Campbell NCSU ST-503 HW 3}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
\subtitle{Chapter 14 Problems 2,3,6,30,31 Rice, John A. Mathematical Statistics
and Data Analysis, Cengage}
  \author{Bruce Campbell}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{12 September, 2017}

\usepackage{bbm}

\begin{document}
\maketitle

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\subsection{Problem 14.2}\label{problem-14.2}

Plot \((x,y)\) for the following data points;

\begin{table}[]
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{lllllllllll}
x & .34 & 1.38 & -.65 & .68 & 1.40 & -.88 & -.30 & -1.18 & .50 & -1.75 \\
y & .27 & 1.34 & -.53 & .35 & 1.28 & -.98 & -.72 & -.81  & .64 & -1.59
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.34}\NormalTok{, }\FloatTok{1.38}\NormalTok{, }\OperatorTok{-}\FloatTok{0.65}\NormalTok{, }\FloatTok{0.68}\NormalTok{, }\FloatTok{1.4}\NormalTok{, }\OperatorTok{-}\FloatTok{0.88}\NormalTok{, }\OperatorTok{-}\FloatTok{0.3}\NormalTok{, }\OperatorTok{-}\FloatTok{1.18}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\OperatorTok{-}\FloatTok{1.75}\NormalTok{)}
\NormalTok{y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{0.27}\NormalTok{, }\FloatTok{1.34}\NormalTok{, }\OperatorTok{-}\FloatTok{0.53}\NormalTok{, }\FloatTok{0.35}\NormalTok{, }\FloatTok{1.28}\NormalTok{, }\OperatorTok{-}\FloatTok{0.98}\NormalTok{, }\OperatorTok{-}\FloatTok{0.72}\NormalTok{, }\OperatorTok{-}\FloatTok{0.81}\NormalTok{, }\FloatTok{0.64}\NormalTok{, }\OperatorTok{-}\FloatTok{1.59}\NormalTok{)}

\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x, }\DataTypeTok{y =}\NormalTok{ y)}
\NormalTok{p <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ df, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x, }\DataTypeTok{y =}\NormalTok{ y)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{show.legend =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{ggtitle}\NormalTok{(}\KeywordTok{TeX}\NormalTok{(}\StringTok{"$(X,Y)$"}\NormalTok{))}

\NormalTok{lm.fit.xy <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(x }\OperatorTok{~}\StringTok{ }\NormalTok{y, }\DataTypeTok{data =}\NormalTok{ df)}
\NormalTok{p <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_abline}\NormalTok{(}\DataTypeTok{intercept =}\NormalTok{ lm.fit.xy}\OperatorTok{$}\NormalTok{coefficients[}\StringTok{"(Intercept)"}\NormalTok{], }\DataTypeTok{slope =}\NormalTok{ lm.fit.xy}\OperatorTok{$}\NormalTok{coefficients[}\StringTok{"y"}\NormalTok{], }
    \DataTypeTok{color =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{show.legend =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\DataTypeTok{legend =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{show_guide =} \OtherTok{TRUE}\NormalTok{, }
    \DataTypeTok{guide =} \StringTok{"legend"}\NormalTok{)}

\NormalTok{lm.fit.yx <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{x, }\DataTypeTok{data =}\NormalTok{ df)}
\NormalTok{p <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_abline}\NormalTok{(}\DataTypeTok{intercept =}\NormalTok{ lm.fit.yx}\OperatorTok{$}\NormalTok{coefficients[}\StringTok{"(Intercept)"}\NormalTok{], }\DataTypeTok{slope =}\NormalTok{ lm.fit.yx}\OperatorTok{$}\NormalTok{coefficients[}\StringTok{"x"}\NormalTok{], }
    \DataTypeTok{color =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{show.legend =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{legend =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{show_guide =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{guide =} \StringTok{"legend"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{guides}\NormalTok{(}\DataTypeTok{shape =} \KeywordTok{guide_legend}\NormalTok{(}\DataTypeTok{override.aes =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{linetype =} \DecValTok{0}\NormalTok{)))}
\NormalTok{p}
\end{Highlighting}
\end{Shaded}

\includegraphics{BruceCampbell_ST503_HW3_RiceCh14_Pblms_2_3_5_30_31_files/figure-latex/unnamed-chunk-1-1.pdf}

\subsubsection{Fit a line y = a + bx by the method of least squares, and
sketch it on the
plot.}\label{fit-a-line-y-a-bx-by-the-method-of-least-squares-and-sketch-it-on-the-plot.}

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\alph{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
    Fit a line x = c + dy by the method of least squares, and sketch it
    on the plot.
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\alph{enumi}.}
  \setcounter{enumi}{2}
  \tightlist
  \item
    Are the lines in parts (a) and (b) the same? If not, why not?
  \end{enumerate}
\end{itemize}

The lines are not the same. Geometrically, we're minimizing errors in
the y direction for the model \(y \sim x\) and for the model
\(x \sim y\) we're minimizing errors in the x direction. Going further
we can work out when we might see equality in the two regression lines.

Let's denote the two lines by \(y = \beta_0 + \beta_1 x\) and
\(x = \beta_0' + \beta_1' y\) We know that
\(\bar{y} = \beta_0 + \beta_1 \bar{x}\) and
\(\bar{x} = \beta_0' + \beta_1' \bar{y}\) The point
\((\bar{x},\bar{y})\) is where the two regression lines above intersect.
Now we also know that \((\beta_0,0)\) is a point on
\(y = \beta_0 + \beta_1 x\) and that \((0,\beta_0')\) is a point on
\(x = \beta_0' + \beta_1' y\). The two lines will only be the same when
\(\beta_0=\beta_0'=0\). We can go to the derivation of the values of
\(\beta_0 ,\; \beta_0'\) in the case of simple linear regression and ask
about the conditions in which we will see \(\beta_0=\beta_0'=0\). We
won't show the algebra here, but if we did it right the data constraints
for equality of the regression lines is

\[ \frac{\bar{x}}{\bar{y}} = \frac{\hat{\sigma_x^2}}{\hat{\sigma_y^2}}\]

\subsection{Problem 14.3}\label{problem-14.3}

Show that when
\(y_i = \mu + \epsilon_i \ni e_i \;\;iid \,\; : \; E[\epsilon]=0 \; Var(\epsilon_i)=\sigma^2\)
we have \(\bar{y}\) is the least squares estimate for \(\mu\)

\[ S(\mu) = \sum (y_i - \mu)^2 \] Taking derivatives and setting equal
to zero we have that

\[\frac{\partial S}{\partial \mu} = 0 = -2 \; \sum (y_i - mu) \implies \sum y_i = n \mu \]
So \(\hat{\mu} = \bar{y}\)

\subsection{Problem 14.5}\label{problem-14.5}

\emph{Three objects are located on a line at points p1 \textless{} p2
\textless{} p3. These locations are not precisely known. A surveyor
makes the following measurements: a. He stands at the origin and
measures the three distances from there to p1, p2, p3. Let these
measurements be denoted by Y1, Y2, Y3. b. He goes to p1 and measures the
distances from there to p2 and p3. Let these measurements be denoted by
Y4, Y5. c. He goes to p2 and measures the distance from there to p3.
Denote this measurement by Y6.He thus makes six measurements in all, and
they are all subject to error. In order to estimate the values p1, p2,
p3, he decides to combine all the measurements by the method of least
squares. Using matrix notation, explain clearly how the least squares
estimates would be calculated (you don't have to do the actual
calculations).}

Rice, John A.. Mathematical Statistics and Data Analysis (Available 2010
Titles Enhanced Web Assign) (Page 592). Cengage Textbook. Kindle
Edition.

The predictors are \(X_i \in \{-1,0,1\}\) there will be three of them
corresponding to the three objects. We'll be adding vectors to determine
how the measurement was made. The coefficients are \(d_1, d_2, d_3\) and
these will denote the unknown distances. There is no intercept in this
model.

The matrix equation that needs to be solve in this case is

\[ \textbf{Y} = \textbf{X} \textbf{d} \] Where

\[Y =\left(
\begin{array}{c}
Y_1\\
Y_2\\
Y_3\\
Y_4\\
Y_5\\
Y_6
\end{array}
\right) =
\left(
\begin{array}{ccc}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1\\
-1 & 1 & 0\\
-1 & 0 & 1\\
0 & -1 & 1
\end{array}
\right)
\left(
\begin{array}{c}
d_1 \\
d_2 \\
d_3
\end{array}
\right)
\]

The matrix solution is given by

\[(\textbf{X}^\intercal \textbf{X} )^{-1} \;  \textbf{X}^\intercal \textbf{Y}  = \hat{\textbf{d}}\]

which is derived by solving the least squares problem for the model
\(\textbf{Y} = \textbf{X} \textbf{d} + \boldsymbol\epsilon\) In practice
the matrix equation is solved numerically using the QR matrix
factorization.

\subsection{Problem 14.30}\label{problem-14.30}

Find \(Var(\bar{X})\) where

\[ \textbf{X} = (X_1, \ldots , X_n) \ni Var(X_i)=\sigma \; \forall \; i \; Cov(X_i,X_j)= \rho \, \sigma \; \forall \; i \neq j\]

\[\Sigma_{X \; X} = 
\left(\begin{array}{cccc}
\sigma^2 & \rho\sigma^2 & \cdots & \rho\sigma^2  \\
\rho\sigma^2 & \sigma^2 & \cdots & \rho\sigma^2  \\
\vdots & \vdots & \ddots & \vdots  \\
\rho\sigma^2 & \rho\sigma^2 & \cdots & \sigma^2 
\end{array}
\right)
\] Now consider the mean as a vector.

\[Y = \frac{1}{n} \textbf{1}^\intercal X = \bar{X} \in \mathbb{R}^1\] We
have that

\[\Sigma_{Y \, Y} = \frac{1}{n} \textbf{1}^\intercal \;\Sigma_{X  X} \;\frac{1}{n} \textbf{1} =
\frac{1}{n} \textbf{1}^\intercal 
\left(\begin{array}{c}
\sigma^2 + (n-1)\rho\sigma^2  \\
\vdots  \\
\sigma^2 + (n-1)\rho\sigma^2  \\
\end{array}
\right)=
\frac{\sigma^2}{n} (1 + (n-1)\rho)
\] Now by definition \(\Sigma_{Y \, Y}=Var(\bar{X})\)

\subsection{Problem 14.31}\label{problem-14.31}

Let \[Z= \left(\begin{array}{c}
Z_1  \\
Z_2  \\
Z_3  \\
Z_4  
\end{array}
\right)\in \mathbb{R}^4\] and \(\Sigma_{Z \, Z} = \sigma^2 I\)\$

\[U = Z_1 + Z_2 + Z_3 +Z_4\] and \[V= (Z_1+Z_2) - (Z_3 + Z_4)\] Find
\(Cov(U,V)\)

First let's define \(U\) and \(V\) as linear forms
\(U=\textbf{1}^\intercal Z\) and
\(V=a^\intercal Z \, : \, a=(1,1,-1,-1)\)

Then we have

\[Cov(U,V) = \Sigma_{U \, V} = \textbf{1}^\intercal \,  \Sigma_{Z \, Z}  \, a = \textbf{1}^\intercal 
\left(\begin{array}{c}
\sigma^2  \\
\sigma^2  \\
-\sigma^2  \\
-\sigma^2  
\end{array}
\right) =0\]

We've use the result about the cross covariance of 2 affine transforms
of a random vector;

\[\textbf{Y}= \textbf{A} \textbf{X} \;\; \textbf{Z}= \textbf{B} \textbf{X} \implies \Sigma_{Y \,Z} =\textbf{A}^\intercal \Sigma_{X \,X} \textbf{B} \]
We don't need it and the book doesn't state this but we note that adding
a constant to \(\textbf{Y}\) or \(\textbf{Z}\) does not change the cross
covariance.


\end{document}
